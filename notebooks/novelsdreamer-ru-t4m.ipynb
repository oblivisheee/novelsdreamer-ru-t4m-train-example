{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dependencies\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorboard as tb\n",
    "BASE_FOLDER = '/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/'\n",
    "os.chdir(BASE_FOLDER)\n",
    "from modules.transformer_custom import Transformer\n",
    "from modules.regularization import RegularizedDenseLayer\n",
    "from modules.create_config import transformer_config, metrics_config\n",
    "from modules.tf_text_postprocess import TextPostprocessor\n",
    "from modules.datagen import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name='novelsdreamer_test_2'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Transformer layer\n",
    "config = transformer_config()\n",
    "config_metrics = metrics_config()\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(config[\"input_vocab_size\"], config[\"d_model\"])\n",
    "regularized_layer = RegularizedDenseLayer(config[\"d_model\"])\n",
    "\n",
    "model = Transformer(config[\"num_layers\"], config[\"d_model\"], config[\"num_heads\"], config[\"dff\"],\n",
    "                          config[\"input_vocab_size\"], config[\"input_vocab_size\"], pe_input=config[\"maximum_position_encoding\"],\n",
    "                          pe_target=config[\"maximum_position_encoding\"], rate=config[\"dropout_rate\"], embedding=embedding_layer, regularized_layer=regularized_layer)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='auto')\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(name='Adam',learning_rate=0.001,\n",
    "                                     epsilon=1e-8, amsgrad=True,\n",
    "                                     beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=config_metrics['accuracy_set']), \n",
    "           tf.keras.metrics.MeanSquaredError(name=config_metrics['mean_sq_error']), \n",
    "           tf.keras.metrics.Precision(thresholds=config_metrics['thresholds'], name=config_metrics['precision']),]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_object, metrics=metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data info: 2 classes, 2 samples\n",
      "Valid data info: 2 classes, 2 samples\n"
     ]
    }
   ],
   "source": [
    "MAIN_DATASET_DIR = 'dataset'\n",
    "TRAIN_DATASET_DIR = os.path.join(MAIN_DATASET_DIR, 'train')\n",
    "VALID_DATASET_DIR = os.path.join(MAIN_DATASET_DIR, 'valid')\n",
    "\n",
    "datagen = DataGenerator(MAIN_DATASET_DIR, TRAIN_DATASET_DIR, VALID_DATASET_DIR, session_name=session_name)\n",
    "(train_english, train_russian), (valid_english, valid_russian) = datagen.generate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Epoch 1 Loss 4.8064 Validation Loss 4.9785\n",
      "INFO:tensorflow:Beam search result: [[[52], 1.24537201452603], [[106], 1.7736237314541807], [[103], 1.799550593946515]]\n",
      "INFO:tensorflow:Epoch 1 finished.\n",
      "INFO:tensorflow:Model of 1 epoch saved in novelsdreamer_test_2/results/epoch_models/novelsdreamer-ru-t4m_epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:15<02:22, 15.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Epoch 2 Loss 4.9528 Validation Loss 4.9785\n",
      "INFO:tensorflow:Beam search result: [[[52], 1.24537201452603], [[106], 1.7736237314541807], [[103], 1.799550593946515]]\n",
      "INFO:tensorflow:Epoch 2 finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:22<03:22, 22.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mfit_model(train_english\u001b[39m=\u001b[39mtrain_english, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                          train_russian\u001b[39m=\u001b[39mtrain_russian,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                          valid_english\u001b[39m=\u001b[39mvalid_english,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                          valid_russian\u001b[39m=\u001b[39mvalid_russian,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                          epochs\u001b[39m=\u001b[39mepochs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                          session_name\u001b[39m=\u001b[39msession_name,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                          shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                          save_model_each_epoch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/notebooks/novelsdreamer-ru-t4m.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                          model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnovelsdreamer-ru-t4m\u001b[39m\u001b[39m'\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, gradient_accumulation_steps\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/novelsdreamer-ru-t4m/modules/transformer_custom.py:320\u001b[0m, in \u001b[0;36mTransformer.fit_model\u001b[0;34m(self, train_english, train_russian, valid_english, valid_russian, epochs, model_name, save_model_each_epoch, shuffle, session_name, save_path_epoch, final_save_path, batch_size, gradient_accumulation_steps)\u001b[0m\n\u001b[1;32m    318\u001b[0m way_to_save_time \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(session_name, save_path_epoch, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_epoch_\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    319\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_weights(way_to_save_time\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    321\u001b[0m     tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mModel of \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m epoch saved in \u001b[39m\u001b[39m{\u001b[39;00mway_to_save_time\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    322\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/engine/training.py:2898\u001b[0m, in \u001b[0;36mModel.save_weights\u001b[0;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[1;32m   2834\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[1;32m   2835\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_weights\u001b[39m(\n\u001b[1;32m   2836\u001b[0m     \u001b[39mself\u001b[39m, filepath, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_format\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2837\u001b[0m ):\n\u001b[1;32m   2838\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Saves all layer weights.\u001b[39;00m\n\u001b[1;32m   2839\u001b[0m \n\u001b[1;32m   2840\u001b[0m \u001b[39m    Either saves in HDF5 or in TensorFlow format based on the `save_format`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[39m            HDF5 format.\u001b[39;00m\n\u001b[1;32m   2897\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2898\u001b[0m     saving_api\u001b[39m.\u001b[39msave_weights(\n\u001b[1;32m   2899\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   2900\u001b[0m         filepath\u001b[39m=\u001b[39mfilepath,\n\u001b[1;32m   2901\u001b[0m         overwrite\u001b[39m=\u001b[39moverwrite,\n\u001b[1;32m   2902\u001b[0m         save_format\u001b[39m=\u001b[39msave_format,\n\u001b[1;32m   2903\u001b[0m         options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m   2904\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/saving/saving_api.py:230\u001b[0m, in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     saving_lib\u001b[39m.\u001b[39msave_weights_only(model, filepath)\n\u001b[1;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     legacy_sm_saving_lib\u001b[39m.\u001b[39msave_weights(\n\u001b[1;32m    231\u001b[0m         model, filepath, overwrite\u001b[39m=\u001b[39moverwrite, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    232\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/saving/legacy/save.py:366\u001b[0m, in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m save_format \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mh5\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    365\u001b[0m     \u001b[39mwith\u001b[39;00m h5py\u001b[39m.\u001b[39mFile(filepath, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 366\u001b[0m         hdf5_format\u001b[39m.\u001b[39msave_weights_to_hdf5_group(f, model)\n\u001b[1;32m    367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    369\u001b[0m         \u001b[39m# Call `get_session` to initialize any uninitialized variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/saving/legacy/hdf5_format.py:746\u001b[0m, in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    744\u001b[0m     g \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mcreate_group(layer\u001b[39m.\u001b[39mname)\n\u001b[1;32m    745\u001b[0m     weights \u001b[39m=\u001b[39m _legacy_weights(layer)\n\u001b[0;32m--> 746\u001b[0m     save_subset_weights_to_hdf5_group(g, weights)\n\u001b[1;32m    747\u001b[0m weights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39m_trainable_weights \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39m_non_trainable_weights\n\u001b[1;32m    748\u001b[0m g \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mcreate_group(\u001b[39m\"\u001b[39m\u001b[39mtop_level_model_weights\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/saving/legacy/hdf5_format.py:723\u001b[0m, in \u001b[0;36msave_subset_weights_to_hdf5_group\u001b[0;34m(f, weights)\u001b[0m\n\u001b[1;32m    721\u001b[0m     param_dset[()] \u001b[39m=\u001b[39m val\n\u001b[1;32m    722\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m     param_dset[:] \u001b[39m=\u001b[39m val\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/h5py/_hl/dataset.py:965\u001b[0m, in \u001b[0;36mDataset.__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    962\u001b[0m     mtype \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    964\u001b[0m \u001b[39m# Perform the dataspace selection\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m selection \u001b[39m=\u001b[39m sel\u001b[39m.\u001b[39mselect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, args, dataset\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n\u001b[1;32m    967\u001b[0m \u001b[39mif\u001b[39;00m selection\u001b[39m.\u001b[39mnselect \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/h5py/_hl/selections.py:77\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(shape, args, dataset)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[39mreturn\u001b[39;00m Selection(shape, spaceid\u001b[39m=\u001b[39msid)\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m dataset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     selector \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39m_selector\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     space \u001b[39m=\u001b[39m h5s\u001b[39m.\u001b[39mcreate_simple(shape)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/h5py/_hl/dataset.py:514\u001b[0m, in \u001b[0;36mDataset._selector\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_selector\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_props:\n\u001b[1;32m    512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_props[\u001b[39m'\u001b[39m\u001b[39m_selector\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 514\u001b[0m slr \u001b[39m=\u001b[39m _selector\u001b[39m.\u001b[39mSelector(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid\u001b[39m.\u001b[39mget_space())\n\u001b[1;32m    516\u001b[0m \u001b[39m# If the file is read-only, cache the reader to speed up future uses.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39m# This cache is invalidated by .refresh() when using SWMR.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readonly:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "epochs = 10\n",
    "model.fit_model(train_english=train_english, \n",
    "                         train_russian=train_russian,\n",
    "                         valid_english=valid_english,\n",
    "                         valid_russian=valid_russian,\n",
    "                         epochs=epochs,\n",
    "                         session_name=session_name,\n",
    "                         batch_size=32, gradient_accumulation_steps=5,\n",
    "                         shuffle=True,\n",
    "                         save_model_each_epoch=True,\n",
    "                         model_name='novelsdreamer-ru-t4m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('path_to_saved_weights.h5')  # replace with the path to your saved weights\n",
    "input_sentence = \"your_input_sentence\"  # replace with your input sentence\n",
    "translated_sentence = model.translate(input_sentence)\n",
    "print(translated_sentence)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
