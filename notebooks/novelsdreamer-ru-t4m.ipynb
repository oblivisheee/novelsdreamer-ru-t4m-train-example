{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dependencies\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorboard as tb\n",
    "BASE_FOLDER = '/Users/oblivisheee/Documents/GitHub/novelsdreamer-ru-t4m/'\n",
    "os.chdir(BASE_FOLDER)\n",
    "from modules.transformer_custom import Transformer\n",
    "from modules.regularization import RegularizedDenseLayer\n",
    "from modules.create_config import transformer_config, trainer_config, metrics_config\n",
    "from modules.tf_text_postprocess import TextPostprocessor\n",
    "from modules.datagen import DataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Transformer layer\n",
    "config = transformer_config()\n",
    "config_train = trainer_config()\n",
    "config_metrics = metrics_config()\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(config[\"input_vocab_size\"], config[\"d_model\"])\n",
    "\n",
    "model = Transformer(config[\"num_layers\"], config[\"d_model\"], config[\"num_heads\"], config[\"dff\"],\n",
    "                          config[\"input_vocab_size\"], config[\"input_vocab_size\"], pe_input=config[\"maximum_position_encoding\"],\n",
    "                          pe_target=config[\"maximum_position_encoding\"], rate=config[\"dropout_rate\"], embedding=embedding_layer)\n",
    "\n",
    "regularized_layer = RegularizedDenseLayer(config[\"d_model\"])\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=config_train['loss_reduction'])\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=config_train['learning_rate'])\n",
    "\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=config_metrics['accuracy_set']), \n",
    "           tf.keras.metrics.MeanSquaredError(name=config_metrics['mean_sq_error']), \n",
    "           tf.keras.metrics.Precision(thresholds=0.5, name=config_metrics['precision']),]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_object, metrics=metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'russian': [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>], 'english': [<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 4.], dtype=float32)>]}\n",
      "{'russian': [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>], 'english': [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.], dtype=float32)>]}\n",
      "Train data info: 2 classes, 2 samples\n",
      "Valid data info: 2 classes, 2 samples\n"
     ]
    }
   ],
   "source": [
    "MAIN_DATASET_DIR = 'dataset'\n",
    "TRAIN_DATASET_DIR = os.path.join(MAIN_DATASET_DIR, 'train')\n",
    "VALID_DATASET_DIR = os.path.join(MAIN_DATASET_DIR, 'valid')\n",
    "\n",
    "datagen = DataGenerator(TRAIN_DATASET_DIR, VALID_DATASET_DIR)\n",
    "(train_english, train_russian), (valid_english, valid_russian) = datagen.generate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Epoch 1 Loss 10.8152 Validation Loss 10.6063\n",
      "INFO:tensorflow:Epoch 1 finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:14<11:49, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Epoch 2 Loss 10.5868 Validation Loss 10.3131\n",
      "INFO:tensorflow:Epoch 2 finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:25<10:11, 12.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m epochs \u001b[39m=\u001b[39m config_train[\u001b[39m'\u001b[39m\u001b[39mepoch_train\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m model\u001b[39m.\u001b[39mfit_model(train_english, \n\u001b[1;32m      4\u001b[0m                          train_russian,\n\u001b[1;32m      5\u001b[0m                          valid_english,\n\u001b[1;32m      6\u001b[0m                          valid_russian,\n\u001b[1;32m      7\u001b[0m                          epochs\u001b[39m=\u001b[39mepochs,\n\u001b[1;32m      8\u001b[0m                          save_model_each_epoch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m                          model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnovelsdreamer-ru-t4m\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/novelsdreamer-ru-t4m/modules/transformer_custom.py:256\u001b[0m, in \u001b[0;36mTransformer.fit_model\u001b[0;34m(self, train_english, train_russian, valid_english, valid_russian, epochs, model_name, save_model_each_epoch, save_path_epoch, final_save_path)\u001b[0m\n\u001b[1;32m    254\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(train_russian_tensor, predictions)\n\u001b[1;32m    255\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[0;32m--> 256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(gradients, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    258\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mupdate_state(train_russian_tensor, predictions)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py:747\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    744\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_gradients(grads_and_vars)\n\u001b[1;32m    745\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[0;32m--> 747\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39minterim\u001b[39m.\u001b[39mmaybe_merge_call(\n\u001b[1;32m    748\u001b[0m     functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    749\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distributed_apply, apply_state\u001b[39m=\u001b[39mapply_state\n\u001b[1;32m    750\u001b[0m     ),\n\u001b[1;32m    751\u001b[0m     strategy,\n\u001b[1;32m    752\u001b[0m     grads_and_vars,\n\u001b[1;32m    753\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[1;32m    754\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[39mreturn\u001b[39;00m distribution_strategy_context\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py:806\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39mwith\u001b[39;00m distribution\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mcolocate_vars_with(var):\n\u001b[1;32m    801\u001b[0m     \u001b[39mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[1;32m    802\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    803\u001b[0m         \u001b[39mif\u001b[39;00m eagerly_outside_functions\n\u001b[1;32m    804\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mupdate_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m var\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mname\n\u001b[1;32m    805\u001b[0m     ):\n\u001b[0;32m--> 806\u001b[0m         update_op \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m    807\u001b[0m             var,\n\u001b[1;32m    808\u001b[0m             apply_grad_to_update_var,\n\u001b[1;32m    809\u001b[0m             args\u001b[39m=\u001b[39m(grad,),\n\u001b[1;32m    810\u001b[0m             group\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    811\u001b[0m         )\n\u001b[1;32m    812\u001b[0m         \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39min_cross_replica_context():\n\u001b[1;32m    813\u001b[0m             \u001b[39m# In cross-replica context, extended.update returns\u001b[39;00m\n\u001b[1;32m    814\u001b[0m             \u001b[39m# a list of update ops from all replicas\u001b[39;00m\n\u001b[1;32m    815\u001b[0m             \u001b[39m# (group=False).\u001b[39;00m\n\u001b[1;32m    816\u001b[0m             update_ops\u001b[39m.\u001b[39mextend(update_op)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   2635\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2636\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3710\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3708\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(args), kwargs, group)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3716\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3713\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3717\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n\u001b[1;32m   3718\u001b[0m       \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py:785\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mapply_state\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_apply_args:\n\u001b[1;32m    784\u001b[0m     apply_kwargs[\u001b[39m\"\u001b[39m\u001b[39mapply_state\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m apply_state\n\u001b[0;32m--> 785\u001b[0m update_op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resource_apply_dense(grad, var, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mapply_kwargs)\n\u001b[1;32m    786\u001b[0m \u001b[39mif\u001b[39;00m var\u001b[39m.\u001b[39mconstraint \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies([update_op]):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/optimizers/legacy/adam.py:177\u001b[0m, in \u001b[0;36mAdam._resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    172\u001b[0m coefficients \u001b[39m=\u001b[39m (apply_state \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\n\u001b[1;32m    173\u001b[0m     (var_device, var_dtype)\n\u001b[1;32m    174\u001b[0m ) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fallback_apply_state(var_device, var_dtype)\n\u001b[1;32m    176\u001b[0m m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_slot(var, \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 177\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_slot(var, \u001b[39m\"\u001b[39m\u001b[39mv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamsgrad:\n\u001b[1;32m    180\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mraw_ops\u001b[39m.\u001b[39mResourceApplyAdam(\n\u001b[1;32m    181\u001b[0m         var\u001b[39m=\u001b[39mvar\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    182\u001b[0m         m\u001b[39m=\u001b[39mm\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m         use_locking\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_locking,\n\u001b[1;32m    192\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py:1074\u001b[0m, in \u001b[0;36mOptimizerV2.get_slot\u001b[0;34m(self, var, slot_name)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_slot\u001b[39m(\u001b[39mself\u001b[39m, var, slot_name):\n\u001b[0;32m-> 1074\u001b[0m     var_key \u001b[39m=\u001b[39m _var_key(var)\n\u001b[1;32m   1075\u001b[0m     slot_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slots[var_key]\n\u001b[1;32m   1076\u001b[0m     slot_variable \u001b[39m=\u001b[39m slot_dict[slot_name]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py:1660\u001b[0m, in \u001b[0;36m_var_key\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(var, \u001b[39m\"\u001b[39m\u001b[39m_distributed_container\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1656\u001b[0m     var \u001b[39m=\u001b[39m var\u001b[39m.\u001b[39m_distributed_container()\n\u001b[1;32m   1657\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m   1658\u001b[0m     tf_utils\u001b[39m.\u001b[39mis_extension_type(var)\n\u001b[1;32m   1659\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(var, \u001b[39m\"\u001b[39m\u001b[39mhandle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1660\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(var\u001b[39m.\u001b[39mhandle, \u001b[39m\"\u001b[39m\u001b[39m_distributed_container\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1661\u001b[0m ):\n\u001b[1;32m   1662\u001b[0m     \u001b[39m# For ResourceVariables, the _distributed_container attribute\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m     \u001b[39m# is added to their handle tensors.\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m     var \u001b[39m=\u001b[39m var\u001b[39m.\u001b[39mhandle\u001b[39m.\u001b[39m_distributed_container()\n\u001b[1;32m   1665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(var, \u001b[39m\"\u001b[39m\u001b[39m_in_graph_mode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:433\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id \u001b[39m=\u001b[39m uid()\n\u001b[1;32m    431\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m    434\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mravel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranspose\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mtolist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    438\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    439\u001b[0m \u001b[39m      If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    440\u001b[0m \u001b[39m      from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[1;32m    441\u001b[0m \u001b[39m      np_config.enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "epochs = config_train['epoch_train']\n",
    "model.fit_model(train_english, \n",
    "                         train_russian,\n",
    "                         valid_english,\n",
    "                         valid_russian,\n",
    "                         epochs=epochs,\n",
    "                         save_model_each_epoch=True,\n",
    "                         model_name='novelsdreamer-ru-t4m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = config_train['epoch_train']\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_english.tolist(), train_russian.tolist()))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_english.tolist(), valid_russian.tolist()))\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          validation_data=valid_dataset,\n",
    "          epochs=epochs,\n",
    "          verbose='auto',\n",
    "          shuffle=True, workers=4, validation_freq=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
